Задание:
Установите на вашем удаленном сервере Open Distro с доступом из интернета и настройте в нем доступ с Basic Auth данными open:distro (пользователя добавьте через Kibana).
Установите на вашей виртуальной машине fluent-bit.
Напишите конфигурацию для fluent-bit, которая будет отправлять все логи из файла /var/log/fluent на удаленный сервер в формате Logstash с префиксом fbit и автоматически генерировать идентификатор для сообщений
На локальной виртуальной машине запишите в файл /var/log/fluent сообщение Mom, I'm in Kibana!.
Проверьте наличие этой записи в логе через Kibana.
На проверку отправьте URL для доступа к Kibana, время отправки сообщения и конфигурационный файл fluent-bit.


****************************************************************************
Решение
****************************************************************************
Ефошкин Максим Вячеславович
ОТПРАВЛЕНО
15.09.2022 15:29
1. Установка
address: 130.193.34.87
Поднял федору-35

2. Установите на вашем удаленном сервере Open Distro с доступом из интернета и настройте в нем доступ с Basic Auth данными open:distro (пользователя добавьте через Kibana).
Open Distro переходит на opensearch

"
It's time to upgrade to OpenSearch!
The Open Distro project bundled open source distributions of Elasticsearch and Kibana with Apache-2.0-licensed plugins that gave users enterprise-grade features, security, and analytics tools. In the two years since it launched, builders all over the world have used Open Distro to power their applications.

Open source Elasticsearch and Kibana 7.10.2 will soon be end of life, and are no longer receiving active development, security patches, or bugfixes. All users should be running software that receives timely security patches. The OpenSearch project was launched to provide a path forward for open source Elasticsearch and Open Distro users that ensures they always have access to security and new innovation.

Now is the time to migrate to OpenSearch to take advantage of the newest features, performance improvements, bugfixes, and security patches. See what's so great about OpenSearch and get help migrating.
"

Поэтому буду ставить OpenSearch
mkdir /opt/opensearch
cd /opt/opensearch
wget https://artifacts.opensearch.org/releases/bundle/opensearch/2.2.1/opensearch-2.2.1-linux-x64.rpm
dnf install opensearch-2.2.1-linux-x64.rpm 

sudo systemctl daemon-reload
sudo systemctl enable opensearch.service
sudo systemctl start opensearch.service

Установка Java
dnf install openjdk*

Проверка
[root@epd1ghv32ao5fna3mo1h opensearch]# curl -XGET https://localhost:9200 -u 'admin:admin' --insecure
{
  "name" : "epd1ghv32ao5fna3mo1h.auto.internal",
  "cluster_name" : "opensearch",
  "cluster_uuid" : "1rd0XItuRLWpQZAu7DESqg",
  "version" : {
    "distribution" : "opensearch",
    "number" : "2.2.1",
    "build_type" : "rpm",
    "build_hash" : "1a1ffa37cd4d8ede3b18275a11908af4d2f087b8",
    "build_date" : "2022-08-30T17:50:46.371234360Z",
    "build_snapshot" : false,
    "lucene_version" : "9.3.0",
    "minimum_wire_compatibility_version" : "7.10.0",
    "minimum_index_compatibility_version" : "7.0.0"
  },
  "tagline" : "The OpenSearch Project: https://opensearch.org/"
}
[root@epd1ghv32ao5fna3mo1h opensearch]# 


Далее ставим OpenSearch Dashboards
так как кибана теперь не свободная она преешла на OpenSearch Dashboards

Качаем
https://artifacts.opensearch.org/releases/bundle/opensearch-dashboards/2.2.1/opensearch-dashboards-2.2.1-linux-x64.rpm
Ставим
dnf install opensearch-dashboards-2.2.1-linux-x64.rpm 

 sudo systemctl daemon-reload
 sudo systemctl enable opensearch-dashboards.service
sudo systemctl start opensearch-dashboards.service


Ставим nginx
dnf install nginx
systemctl enable nginx
systemctl start nginx

Я добавил настройки прокси на внутренние адреса

server {
    listen 80;
    server_name 130.193.34.87;

    location / {
         proxy_pass http://127.0.0.1:5601; # full internal address
         proxy_http_version  1.1;
         proxy_set_header    Host $server_name:$server_port;
         proxy_set_header    X-Forwarded-Host $http_host;    # necessary for proper absolute redirects and TeamCity CSRF check
         proxy_set_header    X-Forwarded-Proto $scheme;
         proxy_set_header    X-Forwarded-For $remote_addr;
         proxy_set_header    Upgrade $http_upgrade; # WebSocket support
      #   proxy_set_header    Connection $connection_upgrade; # WebSocket support
    }
}

server {
    listen 9301;
    server_name 130.193.34.87;

    location / {
         proxy_pass https://127.0.0.1:9300; # full internal address
         proxy_http_version  1.1;
         proxy_set_header    Host $server_name:$server_port;
         proxy_set_header    X-Forwarded-Host $http_host;    # necessary for proper absolute redirects and TeamCity CSRF check
         proxy_set_header    X-Forwarded-Proto $scheme;
         proxy_set_header    X-Forwarded-For $remote_addr;
         proxy_set_header    Upgrade $http_upgrade; # WebSocket support
      #   proxy_set_header    Connection $connection_upgrade; # WebSocket support
    }
}

server {
    listen 9201;
    server_name 130.193.34.87;

    location / {
         proxy_pass https://127.0.0.1:9200; # full internal address
         proxy_http_version  1.1;
         proxy_set_header    Host $server_name:$server_port;
         proxy_set_header    X-Forwarded-Host $http_host;    # necessary for proper absolute redirects and TeamCity CSRF check
         proxy_set_header    X-Forwarded-Proto $scheme;
         proxy_set_header    X-Forwarded-For $remote_addr;
         proxy_set_header    Upgrade $http_upgrade; # WebSocket support
      #   proxy_set_header    Connection $connection_upgrade; # WebSocket support
    }
}


Для справки
( https://habr.com/ru/post/662527/ )

3. Установите на вашей виртуальной машине fluent-bit.
 address: 158.160.9.92
Стандартная установка, но флюент получился пустой без плагинов.
Установка скриптом с сайта производителя
curl https://raw.githubusercontent.com/fluent/fluent-bit/master/install.sh | sh
systemctl enable --now fluent-bit
systemctl status fluent-bit

Чтобы сделать плагины:
git clone https://github.com/fluent/fluent-bit.git
cd fluent-bit
apt install clang
apt install flex
apt install bison
apt-get install pkg-config
apt-get install libssl-dev
apt install libyaml-dev

cmake ../
make

4. Напишите конфигурацию для fluent-bit, которая будет отправлять все логи из файла /var/log/fluent на удаленный сервер в формате Logstash с префиксом fbit и автоматически генерировать идентификатор для сообщений
vi /etc/fluent-bit/fluent-bit.conf
[INPUT]
    name tail
    path /var/log/fluent
    Buffer_Chunk_Size   32000
    Buffer_Max_Size     64000

[OUTPUT]
    name  opensearch
    match *
    Host  130.193.34.87
    Port  9201
    HTTP_User  open
    HTTP_Passwd  distro
    Logstash_Format true
    Logstash_Prefix  fbit
    Generate_ID  On
    Index fluent-bit
    Suppress_Type_Name On


 
 
5. На локальной виртуальной машине запишите в файл /var/log/fluent сообщение Mom, I'm in Kibana!.
Добавил строчку в конфиг rsyslog
local2.*                        /var/log/fluent

logger -p local2.info "Mom, I'm in Kibana!"
chown syslog:adm /var/log/fluent

logger -p local2.info "Mom, I'm in Kibana! and Max"


 На проверку
http://130.193.34.87

Пароль open:distro

Ура получилось!!
ОТВЕТ КУРАТОРА
Алексей Кузнецов (@Hystrix)
ВЫПОЛНЕНО 4
15.09.2022 19:20
Добрый день!

Очень хорошо, одно замечание:

http://130.193.34.87
Пароль open:distro
Выберите глобальный тенант, создайте в нем индекс, чтобы можно было найти сообщение.

15.09.2022 19:28
ВЫПОЛНЕНО 5
Ефошкин Максим Вячеславович
ОТПРАВЛЕНО
15.09.2022 19:28
Спасибо Готово open - login distro - пароль http://130.193.34.87

Только выберите за Today диапазон.

ОТВЕТ КУРАТОРА
Алексей Кузнецов (@Hystrix)
ВЫПОЛНЕНО 5
16.09.2022 07:36
Добрый день!

Отличные знание темы и самостоятельное выполнение сложного задания, кибана доступна, сообщение присутствует, замечаний и вопросов нет!





*****************************************************************************
Теория
*****************************************************************************


LNXA-06 04: Logging. EFK
Описание:
В предыдущих заданиях мы рассматривали решения для работы с логами, которые подразумевают хранение логов в неструктурированном виде. Все, что отличает один лог от другого, — это severity, facility, хост, с которого отправляли, и приложение (еще может быть тег, но все равно, не особо гибко). В рамках этого задания мы рассмотрим другой подход к хранению логов — в виде структурированных объектов.

Логи, как мы уже обсуждали, позволяют нам узнать от приложений, как и что пошло не так. Часто они летят просто в файлы, из которых нам приходится разбирать данные утилитами типа grep, awk, sed или вообще самописными утилитами/скриптами. Однако иногда хочется не искать их самому, а просто ввести запрос как в Google и получить все логи, содержащие ту или иную строку. ElasticSearch (далее ES), который мы будем рассматривать в этих задачах, как раз и был создан для решения таких задач (изначально, на самом деле, других, но под наши задачи важна именно эта цель).

Разберемся же, что такое ElasticSearch — это поисковая система, написанная на Java компанией Elastic. Общение с ней производится по JSON REST API (то есть, в браузере без дополнительных плагинов общаться с ES не получится). Он используется для поиска данных в документах, что позволяет использовать его как нереляционную базу данных, которая умеет хорошо искать данные по заданному тексту среди своих документов. Документы в ES организованы по индексам, что позволяет разделять приходящие документы по логическому имени (скажем, common_logs и super_important_logs).

Особенностью ES является то, что он хорошо справляется с большим количеством документов, а также умеет легко горизонтально расширяться за счет добавления дополнительных нод практически без боли.

В разрезе темы с логами важно сказать, что искать документы можно не только в одном индексе, а в нескольких одновременно. Важность этого мы поймем чуть далее.

Приведем пример запроса к ES, для того чтобы иметь представление, как отправляются данные и что мы получим в итоге:

# curl -XPUT "localhost:9200/blog/post/1?pretty" -d'
{
  "title": "Веселые котята",
  "content": "<p>Смешная история про котят<p>",
  "tags": [
    "котята",
    "смешная история"
  ],
  "cuteness": 7,
  "published_at": "2014-09-12T20:44:42+00:00"
}'

{
  "_index" : "blog",
  "_type" : "post",
  "_id" : "1",
  "_version" : 1,
  "_shards" : {
    "total" : 2,
    "successful" : 1,
    "failed" : 0
  },
  "created" : false
}
Рассмотрим запрос детально:

Мы отправили запрос методом PUT по пути /blog/post/1, тем самым определив индекс (_index) blog, тип сообщения (_type) и идентификатор сообщения (_id) - 1.
В теле (JSON) мы описали объект, в котором есть 4 поля - title, content, tags, cuteness и published_at. У каждого из них свой тип и это важно (текст, текст, массив строк, число и дата).
Пока просто держим это в голове, поскольку к этому документу мы еще вернемся.

Вернемся к проблеме (с точке зрения использования простым человеком), что запросы к ES можно делать только по JSON REST API. Напрашивается же какой-то инструмент, который позволит удобно запрашивать, просматривать и фильтровать логи. Специально для этих целей разработчики ES создали инструмент Kibana.

Kibana

Благодаря нему, мы и получаем ту самую поисковую строку, которая позволит найти все необходимые данные и вывести их для удобного просмотра.

В Kibana можно производить простые запросы прямыми запросами типа Error, что вернет все документы, содержащие эти слова. Но вся сила этой поисковой строки состоит в умении запрашивать с использованием сложных выражений и правил форматирования, подобных тем, что мы использовали при написании скриптов в if/else в bash. Это бывает необходимо, когда мы пользуемся полями документа (мы как раз их отправляли выше). Приведем примеры, связанные с нашим документом:

котята — простой запрос без использования полей;
title:"Веселые котята" — позволит получить документы, в title которого присутствуют слова из переданной строки;
tags:котята — вернет документы, у которых в массиве tags есть котята;
cuteness: [6 TO *] — найдет все документы, у которых милашность выше 6;
NOT tags:песики — отфильтрует из выборки документы, у которых в массиве есть песики;
tags:котята AND cuteness: [6 TO *] — объединение двух условий (AND — требует от документа подходить по двум правилам, а OR — хотя бы по одному).
Кроме формата запросов по умолчанию, который пришел в Kibana и ES из Lucene (билиотека для поиска от фонда Apache), у Kibana существует еще и свой язык запросов, называемый Kibana Query Language (или KQL). Он позволяет писать запросы, которые ближе к SQL и другим запросам, как в языках программирования.

Kibana оперирует понятием Index Patterns — объединение индексов по имени, что может быть очень полезно, если у нас есть индексы, разделенные по дате (к примеру, logs-20.10.01 и logs-20.10.02, но к этому мы еще вернемся). Это позволяет производить запросы сразу на группу индексов, расширяя тем самым ширину выборки.

Хорошо, теперь мы знаем, как хранить документы и искать по ним в удобном графическом интерфейсе. Но как это вообще коррелирует с логами? Кто будет собирать их и класть в ES?

Для этого надо рассмотреть еще один инструмент, разработанный компанией Elastic, — Logstash. Из названия напрашивается цель инструмента — сбор логов для дальнейшего хранения, в том числе в виде документов в ES. Однако, в действительности, Logstash умеет намного больше — его задачей является сбор (input), обработка (filter) и отправка (output) логов на хранение. Как видно, напрашивается определенная аналогия с rsyslog и его модулями. И да, все правильно — концепт приблизительно такой с отличием только в формате передаваемых данных.

Отличительной чертой логов от других документов в ES является наличие поля времени отправки, по которому можно произвести сортировку событий и построить график поступления логов, это вы можете наблюдать на скриншоте выше. В остальном логи — это обычные документы, к которым применимы те же запросы для поиска и фильтрации.

Часто Logstash используют в роли инструмента обработки входящих логов в первозданном виде и их преобразования перед отправкой в ES, однако существуют и другие инструменты для выполнения этой работы. Связано это, в первую очередь, с тем, что Logstash, как и ElasticSearch, написан на Java - не самом ресурсобережном языке, из-за чего не принято ставить Logstash на каждой ноде для сборки логов.

Для этих задач у команды Elastic существует группа отдельных инструментов — Beats. Идея этих инструментов в том, чтобы создать маленькие инструменты, которые собирают конкретные данные и далее могут отправлять логи на обработку либо напрямую в ES, либо с предварительной обработкой Logstash.

Связку ElasticSearch, Logstash и Kibana принято называть ELK стеком - эдакое ванильное решение от одного разработчика, которое будет работать хорошо. Однако в реальности часто компонента под буквой L может быть заменена на другие, более производительные или гибкие решения.

К примеру, утилита fluentd, написанная на Ruby, позволяет выполнять задачи сборки, обработки и отправки логов куда угодно и практически в любом формате, благодаря модульному подходу этого инструмента и возможности установить необходимый конкретно для вас плагин, когда вам это нужно. Так, модуль fluent-plugin-elasticsearch позволяет отправлять логи в ElasticSearch.

Вместе с Fluentd мы получаем другую вариацию стека, которая используется достаточно широко, — EFK.

Разберем пример конфигурации fluentd:

<source>
 @type tail
 path /var/log/syslog
 pos_file /var/log/fluentd-syslog.log.pos
 time_format %Y-%m-%dT%H:%M:%S.%LZ
 tag system
</source>
<match *.*>
 @type copy
 <store>
   @type stdout
 </store>
 <store>
    @type elasticsearch
    logstash_format true
	logstash_prefix fluentd
    flush_interval 10s
	host "#{ENV['OUTPUT_HOST']}"
    port "#{ENV['OUTPUT_PORT']}"
 </store>
</match>
Согласно этому файлу, все логи из файла /var/log/syslog будут собираться и выводиться в вывод fluentd и в то же время — в ElasticSearch на удаленном сервере в индексы, начинающиеся на fluentd и заканчивающиеся на дату, когда был записан лог (и вот тут нам и может пригодиться Index Pattern в Kibana).

Хотя Fluentd является легким по ресурсам инструментом в сравнении с Logstash, он все равно может занимать мегабайт 20 на каждом из хостов (такова цена универсальности). Поэтому у Fluentd есть младший шустрый брат, полностью написанный на C, — Fluent Bit, у которого реализован фиксированный набор пакетов input и output. Важно то, что в отличие от Fluentd, Fluent Bit умеет отправлять в 2 вида серверов — Fluent(d/bit) (протокол Forward) и в ElasticSearch, что позволяет организовать каскад необходимой сложности для обработки логов.

Кроме оригинальной реализации ELK стека, в которой возможно использовать набор дополнений X-Pack (как бесплатную часть, так и платную), существует версия ElasticSearch и Kibana, освобожденная от проприетарных зависимостей и распространяемая под открытой лицензией. Эту версию называют Open Source (сокращенное OSS). Кроме нее, существует еще одна версия ElasticSearch, разрабатываемая компанией Amazon под названием Open Distro, которая приследует 2 цели:

обойти лицензионное ограничение на использование ElasticSearch в режиме Hosted solution (что запрещено лицензией оригинального продукта);
сохранить возможности X-Pack в том или ином виде для удобства.
В целом, все эти решения имеют право жить, однако в зависимости от того, как и в какой конфигурации вы устанавливаете стек, вам могут потребоваться те или иные ограничения/возможности, которые могут быть в разных версиях, бесплатно или платно.

Перед окончанием теоретической части хотелось бы упомянуть еще 2 инструмента, которые могут пригодиться вам при работе с ElasticSearch:

curator — позволяет управлять жизненным циклом индексов в ElasticSearch (к примеру, настраивать ротацию индексов с необходимой глубиной). В последних версиях часть этой функциональности можно возложить на Kibana c X-Pack или Open Distro.
cerebro — своеобразный административный кабинет по работе с ElasticSearch. Позволяет удобно работать с индексами, шаблонами индексов и другими компонентами вашего ES кластера.
Полезные ссылки:
Elastic company official site
Основы Elasticsearch
5 ключевых достоинств и 3 главных недостатка ELK-стека: разбираемся с Elasticsearch, Logstash и Kibana на реальных Big Data кейсах
Elasticsearch 7.x Cheatsheet
Kibana-мать, или зачем вам вообще нужны логи?
Kibana queries and filters
Lucene (wikipedia)
Kibana Query Language
Собираем, парсим и отдаем логи с помощью Logstash
Beats
Сбор и анализ логов с Fluentd
Elasticsearch, Fluentd, and Kibana: Open Source Log Search and Visualization
Advanced fluentd config
Fluentd and Fluent Bit
Set up X-Pack
Amazon выпустила Open Distro for Elasticsearch (habr)
Curator reference
Cerebro (github)
